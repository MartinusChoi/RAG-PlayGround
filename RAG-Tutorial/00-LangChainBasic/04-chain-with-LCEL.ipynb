{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL을 활용해 Chain 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LCEL (LangChain Expression Language)\n",
    "\n",
    "LCEL은 LangChain Expression Language의 줄임말로, LangChain의 다양한 구성요소를 연결하여 하나의 파이프라인(Chain)으로 만들기 위한 연산자\n",
    "- `|` 연산자를 LCEL이라고 함\n",
    "- `|`는 unix의 파이프 연산자와 유사하며, 서로 다른 구성 요소를 연결하고 한 구성 요소의 결과물을 다음 구성요소의 입력값으로 전달하도록 설정함.\n",
    "- `chain = prompt | llm` 과 같이 사용되며\n",
    "    - 여기서는 완성된 프롬프트가 llm 으로 전달되는 형태로 chian이 구성됨\n",
    "    - 앞에서 부터 순차적으로 체인이 구성됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"{topic}에 대해 {how} 설명해주세요.\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. `invoke()` 호출\n",
    "\n",
    "- chain도 `invoke()` 메서드를 지원함\n",
    "- python 딕셔너리 형태로 입력값을 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain의 LECL(LLM-Enhanced Chain Learning)은 자연어 처리(NLP) 및 대화형 AI 시스템에서 사용되는 혁신적인 접근 방식입니다. LECL은 대규모 언어 모델(LLM)을 활용하여 체인(Chain) 구조를 통해 다양한 작업을 수행하는 방법론입니다. 이 접근 방식은 여러 단계의 프로세스를 통해 데이터를 처리하고, 결과를 생성하며, 사용자와의 상호작용을 개선하는 데 중점을 둡니다.\n",
      "\n",
      "### LECL의 주요 구성 요소\n",
      "\n",
      "1. **체인(Chain)**: LECL은 여러 개의 모듈이나 단계를 연결하여 작업을 수행하는 체인 구조를 사용합니다. 각 단계는 특정 작업을 수행하며, 이전 단계의 출력을 다음 단계의 입력으로 사용합니다.\n",
      "\n",
      "2. **대규모 언어 모델(LLM)**: LECL은 GPT-3, GPT-4와 같은 대규모 언어 모델을 활용하여 자연어 이해 및 생성 작업을 수행합니다. 이러한 모델은 방대한 양의 데이터를 학습하여 높은 수준의 언어 이해 능력을 가지고 있습니다.\n",
      "\n",
      "3. **강화 학습(Enhanced Learning)**: LECL은 모델의 성능을 지속적으로 개선하기 위해 강화 학습 기법을 사용할 수 있습니다. 이를 통해 모델은 사용자 피드백이나 환경 변화에 적응하며, 더 나은 결과를 생성할 수 있습니다.\n",
      "\n",
      "### LECL의 작동 방식\n",
      "\n",
      "1. **입력 처리**: 사용자가 입력한 데이터를 수집하고, 이를 체인 구조의 첫 번째 단계로 전달합니다.\n",
      "\n",
      "2. **단계별 처리**: 각 단계에서는 특정 작업을 수행합니다. 예를 들어, 첫 번째 단계에서는 입력을 분석하고, 두 번째 단계에서는 필요한 정보를 추출하며, 세 번째 단계에서는 최종 결과를 생성합니다.\n",
      "\n",
      "3. **결과 생성**: 마지막 단계에서 생성된 결과는 사용자에게 반환됩니다. 이 과정에서 LLM이 자연어로 결과를 표현하여 사용자와의 상호작용을 원활하게 합니다.\n",
      "\n",
      "4. **피드백 루프**: 사용자의 피드백을 수집하여 모델의 성능을 개선하는 데 활용합니다. 이를 통해 LECL은 지속적으로 학습하고 발전할 수 있습니다.\n",
      "\n",
      "### LECL의 장점\n",
      "\n",
      "- **유연성**: 다양한 작업에 적용할 수 있는 유연한 구조를 가지고 있습니다.\n",
      "- **효율성**: 여러 단계를 통해 복잡한 작업을 효율적으로 처리할 수 있습니다.\n",
      "- **사용자 경험 개선**: 자연어 처리 능력을 통해 사용자와의 상호작용을 개선합니다.\n",
      "\n",
      "### 결론\n",
      "\n",
      "LangChain의 LECL은 대규모 언어 모델을 활용하여 체계적이고 효율적인 방식으로 자연어 처리 작업을 수행하는 혁신적인 접근 방식입니다. 이를 통해 다양한 분야에서 AI 기반의 솔루션을 개발하고, 사용자 경험을 향상시키는 데 기여할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"topic\" : \"LangChain의 LECL\", \"how\" : \"자세히\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LECL, which stands for \"LangChain Event-Driven Chain Language,\" is a framework within the LangChain ecosystem designed to facilitate the development of applications that leverage language models in an event-driven manner. It allows developers to create chains of operations that can respond to specific events, making it easier to build interactive and responsive applications.\n",
      "\n",
      "Key features of LECL include:\n",
      "\n",
      "1. **Event-Driven Architecture**: LECL enables developers to define how their applications should react to various events, such as user inputs, API calls, or other triggers. This architecture supports dynamic and real-time interactions.\n",
      "\n",
      "2. **Modular Design**: The framework promotes a modular approach, allowing developers to create reusable components that can be easily integrated into different applications. This modularity enhances maintainability and scalability.\n",
      "\n",
      "3. **Integration with Language Models**: LECL is designed to work seamlessly with various language models, enabling developers to harness the power of natural language processing in their applications. This integration allows for sophisticated text generation, understanding, and manipulation.\n",
      "\n",
      "4. **Flexibility and Customization**: Developers can customize the behavior of their chains to suit specific use cases, providing the flexibility needed to build tailored solutions.\n",
      "\n",
      "5. **Simplified Development Process**: By providing a structured way to handle events and chain operations, LECL simplifies the development process, allowing developers to focus on building features rather than managing complex workflows.\n",
      "\n",
      "Overall, LECL is a powerful tool for developers looking to create interactive applications that utilize language models in an efficient and organized manner.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"topic\" : \"LangChain의 LECL\", \"how\" : \"영어로\"})\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
